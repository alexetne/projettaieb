# ğŸ“Œ Projet de DÃ©tection d'Intrusions RÃ©seau avec Random Forest

## ğŸ“– Introduction
Ce projet vise Ã  analyser un dataset de trafic rÃ©seau et Ã  construire un modÃ¨le de machine learning basÃ© sur **Random Forest** afin de dÃ©tecter les attaques rÃ©seau. Le dataset utilisÃ© contient diverses caractÃ©ristiques des paquets rÃ©seau ainsi qu'un label indiquant s'il s'agit d'un **trafic normal** ou d'une **attaque**.

---
## ğŸ“‚ Structure du projet
```
â”œâ”€â”€ .gitignore
â”œâ”€â”€ 02-14-2018-2.csv
â”œâ”€â”€ ex1.ipynb
â”œâ”€â”€ ex2.ipynb
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
```

---
## ğŸ“Š DonnÃ©es
### ğŸ“¥ Source des donnÃ©es
Le dataset utilisÃ© est un ensemble de logs rÃ©seau capturÃ©s, contenant les caractÃ©ristiques des paquets et des connexions.

### ğŸ·ï¸ En-tÃªtes principales du dataset
- **Dst Port** : Port de destination
- **Protocol** : Protocole utilisÃ© (TCP, UDP...)
- **Timestamp** : Horodatage du paquet
- **Flow Duration** : DurÃ©e totale du flux
- **Tot Fwd Pkts / Tot Bwd Pkts** : Nombre total de paquets envoyÃ©s/reÃ§us
- **TotLen Fwd Pkts / TotLen Bwd Pkts** : Taille totale des paquets envoyÃ©s/reÃ§us
- **Fwd Pkt Len Max/Min/Mean/Std** : Statistiques sur la taille des paquets en envoi
- **Bwd Pkt Len Max/Min/Mean/Std** : Statistiques sur la taille des paquets en rÃ©ception
- **Flow Byts/s & Flow Pkts/s** : DÃ©bit en bytes et en paquets par seconde
- **Flags TCP (FIN, SYN, ACK, etc.)** : Indicateurs TCP
- **Idle Mean/Std/Max/Min** : Temps d'inactivitÃ© moyen et extrÃªmes
- **Label** : **0 = Normal**, **1 = Attaque**

---
## ğŸ› ï¸ PrÃ©traitement des donnÃ©es
1. **Chargement et exploration des donnÃ©es**
2. **Suppression des doublons**
3. **Gestion des valeurs manquantes** (remplacement par la mÃ©diane, suppression si nÃ©cessaire)
4. **Correction des types de donnÃ©es** (conversion des timestamps, normalisation des valeurs numÃ©riques)
5. **Encodage du label** (binarisation)
6. **Normalisation des caractÃ©ristiques** avec `StandardScaler`

---
## ğŸ§  ModÃ¨le de Machine Learning
### ğŸ“Œ ModÃ¨le utilisÃ© : **Random Forest Classifier**
**HyperparamÃ¨tres optimisÃ©s avec GridSearchCV** :
- `n_estimators = [50, 100, 200]`
- `max_depth = [10, 20, None]`
- `min_samples_split = [2, 5, 10]`

ğŸ“Š **SÃ©paration des donnÃ©es** : 80% EntraÃ®nement | 20% Test

**Ã‰valuation du modÃ¨le** :
- **Accuracy**
- **Precision, Recall, F1-score**
- **Matrice de confusion**
- **ROC-AUC Score**
- **Feature Importance**

---
## ğŸ“ˆ RÃ©sultats et Visualisations
âœ… **Performance du modÃ¨le optimisÃ©** :
- **Accuracy** : `> 90%`
- **Recall** : `> 85%` (bonne capacitÃ© de dÃ©tection des attaques)
- **PrÃ©cision** : `> 80%` (faible taux de faux positifs)
- **AUC ROC** : `> 0.90` (bonne sÃ©paration des classes)

ğŸ“Œ **Visualisations :**
- Matrice de confusion normalisÃ©e
- Courbes ROC et Precision-Recall
- Analyse des Features les plus influentes (SHAP & Feature Importance)

---
## ğŸš€ Recommandations
ğŸ”¹ **Optimisations possibles** :
- Tester d'autres modÃ¨les (**XGBoost, LightGBM, Deep Learning**)
- Ajouter de nouvelles donnÃ©es rÃ©seau pour enrichir l'entraÃ®nement
- Affiner l'Ã©quilibrage des classes (SMOTE, sous-Ã©chantillonnage)
- DÃ©ploiement en **temps rÃ©el** sur un SIEM (Splunk, ELK...)

---
## ğŸ“Œ Comment utiliser ce projet ?
### 1ï¸âƒ£ **CrÃ©ation de l'env**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 2ï¸âƒ£ **Installation des dÃ©p**
```bash
pip install -r requierment.txt
```

---
## ğŸ”— Auteurs et Contributions
Ce projet a Ã©tÃ© dÃ©veloppÃ© par [ETIENNE Alexandre].
Contributions et amÃ©liorations bienvenues ! ğŸš€

ğŸ“© **Contact** : [alex@etienne26.fr]

---
## ğŸ“œ Licence
Ce projet est sous licence **MIT** - Voir `LICENSE` pour plus dâ€™informations.

