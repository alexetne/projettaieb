{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Rapport individuel\n",
    "Chaque étudiant doit rédiger un rapport individuel (10 à 20 pages maximum), structuré comme suit :\n",
    "\n",
    "## a. Définition du problème :\n",
    "- Identifiez la problématique métier à résoudre.\n",
    "- Précisez les objectifs et les exigences du projet.\n",
    "\n",
    "## b. Collecte des données :\n",
    "- Choisissez un dataset pertinent pour votre projet.\n",
    "- Évaluez la qualité et la quantité des données disponibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---  \n",
    "\n",
    "```md\n",
    "# 📊 Analyse Exploratoire d'un Dataset CSV avec Pandas, NumPy, Seaborn et Matplotlib\n",
    "\n",
    "Ce script Python permet d'effectuer une **analyse exploratoire des données (EDA)** sur un fichier **CSV** en utilisant les bibliothèques **Pandas, NumPy, Seaborn et Matplotlib**. Il fournit un aperçu des données, identifie les valeurs manquantes et dupliquées, affiche des statistiques descriptives et génère des visualisations utiles pour comprendre la distribution des données et leur corrélation.\n",
    "\n",
    "## 📌 Prérequis\n",
    "\n",
    "Avant d'exécuter ce script, assurez-vous d'avoir installé les bibliothèques nécessaires avec la commande suivante :\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy seaborn matplotlib\n",
    "```\n",
    "\n",
    "## 📂 Chargement du Dataset\n",
    "\n",
    "Le script commence par charger un fichier CSV nommé **\"02-14-2018-2.csv\"** dans un DataFrame Pandas :\n",
    "\n",
    "```python\n",
    "file_path = \"02-14-2018-2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "```\n",
    "\n",
    "Si le fichier n'est pas dans le même répertoire que le script, vous devrez ajuster le chemin du fichier.\n",
    "\n",
    "## 🔍 1. Aperçu des Données\n",
    "\n",
    "Les premières lignes du dataset sont affichées pour donner un premier aperçu du contenu :\n",
    "\n",
    "```python\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "Cela permet d'identifier rapidement les colonnes et le type de données présentes.\n",
    "\n",
    "## 📃 2. Informations Générales sur le Dataset\n",
    "\n",
    "Le script affiche des informations détaillées sur le dataset, y compris le **nombre total de lignes et de colonnes**, ainsi que les **types de données** :\n",
    "\n",
    "```python\n",
    "print(df.info())\n",
    "```\n",
    "\n",
    "Ce rapport permet de détecter si certaines colonnes contiennent des valeurs **nulles** ou des **types de données incohérents**.\n",
    "\n",
    "## 🔢 3. Nombre de Lignes et Colonnes\n",
    "\n",
    "Le nombre total de **lignes** et **colonnes** du dataset est affiché :\n",
    "\n",
    "```python\n",
    "print(f\"Nombre de lignes : {df.shape[0]}  |  Nombre de colonnes : {df.shape[1]}\")\n",
    "```\n",
    "\n",
    "Cela donne une idée générale de la **taille du dataset**.\n",
    "\n",
    "## ⚠️ 4. Vérification des Valeurs Manquantes\n",
    "\n",
    "Les valeurs manquantes sont identifiées en calculant le nombre de **valeurs nulles par colonne** :\n",
    "\n",
    "```python\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "```\n",
    "\n",
    "Seules les colonnes contenant **des valeurs manquantes** sont affichées. Cela permet d'évaluer si un **nettoyage des données** est nécessaire.\n",
    "\n",
    "## 📊 5. Distribution des Classes (Trafic Normal vs Attaques)\n",
    "\n",
    "Une **visualisation** de la répartition des labels dans le dataset est générée avec Seaborn :\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(y=df['Label'], order=df['Label'].value_counts().index)\n",
    "plt.title(\"📊 Distribution des attaques et du trafic normal\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- La colonne `Label` est supposée contenir des **catégories de trafic** (par ex. \"normal\" vs. \"attaque\").\n",
    "- Un **graphique en barres** est utilisé pour montrer le **nombre d'occurrences** de chaque type de trafic.\n",
    "\n",
    "## 📈 6. Statistiques Descriptives des Variables Numériques\n",
    "\n",
    "Le script affiche un **résumé statistique** des colonnes numériques :\n",
    "\n",
    "```python\n",
    "print(df.describe())\n",
    "```\n",
    "\n",
    "Cela inclut :\n",
    "- **Moyenne (mean)**\n",
    "- **Écart-type (std)**\n",
    "- **Valeurs minimales et maximales**\n",
    "- **Quartiles (25%, 50%, 75%)**\n",
    "\n",
    "Ces informations sont essentielles pour détecter **d'éventuelles anomalies** ou valeurs aberrantes.\n",
    "\n",
    "## 🔄 7. Vérification des Valeurs Dupliquées\n",
    "\n",
    "Le script détecte et affiche le nombre de **lignes dupliquées** dans le dataset :\n",
    "\n",
    "```python\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Nombre de lignes dupliquées : {duplicates}\")\n",
    "```\n",
    "\n",
    "Si des doublons sont détectés, il peut être utile de les supprimer pour éviter des biais dans l'analyse.\n",
    "\n",
    "## 🔬 8. Matrice de Corrélation des 10 Premières Variables\n",
    "\n",
    "Une **matrice de corrélation** est générée pour analyser la **relation entre les variables numériques** :\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr_matrix.iloc[:10, :10], annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"🔍 Matrice de Corrélation (10 premières variables)\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- Seules les **10 premières colonnes** numériques sont affichées.\n",
    "- Une **carte thermique (heatmap)** est utilisée pour mieux visualiser les corrélations.\n",
    "- Une **forte corrélation** (valeurs proches de **+1** ou **-1**) peut indiquer une **redondance** entre certaines variables.\n",
    "\n",
    "## ✅ Conclusion\n",
    "\n",
    "À la fin du script, un message de confirmation est affiché :\n",
    "\n",
    "```python\n",
    "print(\"\\n✅ Évaluation des données terminée !\")\n",
    "```\n",
    "\n",
    "Ce script fournit une **analyse rapide et efficace** d'un dataset CSV, facilitant la **préparation des données** avant une analyse plus approfondie ou un entraînement de modèle machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.font_manager as fm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Define a compatible font to avoid display errors\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'  # Replaces Noto Sans\n",
    "\n",
    "# ✅ Adjust display parameters to avoid truncation\n",
    "pd.options.display.max_rows = 50  # Adjust as needed\n",
    "pd.options.display.max_columns = 20\n",
    "\n",
    "# 📌 Load a CSV file (adjust path according to file location)\n",
    "file_path = \"02-14-2018-2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ✅ Checking and replacing infinite values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 🔹 1. Dataset overview\n",
    "print(\"\\nAperçu des premières lignes du dataset :\")\n",
    "print(df.head())\n",
    "\n",
    "# 🔹 2. General dataset information\n",
    "print(\"\\nInformations générales :\")\n",
    "print(df.info())\n",
    "\n",
    "# 🔹 3. Number of rows and columns\n",
    "print(f\"\\nNombre de lignes : {df.shape[0]}  |  Nombre de colonnes : {df.shape[1]}\")\n",
    "\n",
    "# 🔹 4. Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]  # Keep only columns with zero values\n",
    "if not missing_values.empty:\n",
    "    print(\"\\nColonnes avec valeurs manquantes :\")\n",
    "    print(missing_values)\n",
    "else:\n",
    "    print(\"\\nAucune valeur manquante détectée.\")\n",
    "\n",
    "# 🔹 5. Class distribution (normal traffic vs. attacks)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(y=df['Label'], order=df['Label'].value_counts().index)\n",
    "plt.title(\"Distribution des attaques et du trafic normal\")\n",
    "plt.show()\n",
    "\n",
    "# 🔹 6. Descriptive statistics for numerical variables\n",
    "print(\"\\nCalcul des statistiques descriptives en cours...\")\n",
    "stats_desc = df.describe()\n",
    "\n",
    "# ✅ Save to file to avoid truncated display\n",
    "stats_desc.to_csv(\"statistiques_descriptives.csv\")\n",
    "print(\"\\nStatistiques descriptives enregistrées dans 'statistiques_descriptives.csv'. Ouvrez ce fichier pour voir toutes les valeurs.\")\n",
    "\n",
    "# ✅ Partial display to avoid truncation in the console\n",
    "print(stats_desc.iloc[:, :10])  # Display first 10 columns only\n",
    "\n",
    "# 🔹 7. Checking duplicate values\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNombre de lignes dupliquées : {duplicates}\")\n",
    "\n",
    "# 🔹 8. Correlation matrix for the first 10 variables\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr_matrix.iloc[:10, :10], annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Matrice de Corrélation (10 premières variables)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nÉvaluation des données terminée !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Nettoyage et préparation des données :\n",
    "- Effectuez le nettoyage des données (gestion des doublons, traitement des valeurs manquantes, etc.).\n",
    "- Transformez et formatez les données si nécessaire.\n",
    "- Fusionnez différentes sources de données, le cas échéant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🛠️ Prétraitement des Données avec Pandas, NumPy et Scikit-Learn\n",
    "\n",
    "Ce script effectue un **prétraitement avancé des données** sur un dataset chargé avec **Pandas**. Il supprime les doublons, gère les valeurs manquantes et aberrantes, convertit les types de données, encode les labels et normalise les features avant de sauvegarder le dataset nettoyé.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Prérequis\n",
    "\n",
    "Assurez-vous d'avoir installé les bibliothèques nécessaires avec la commande :\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy seaborn matplotlib scikit-learn\n",
    "```\n",
    "\n",
    "## 🗂️ Chargement des Données\n",
    "\n",
    "Le script suppose que les données sont déjà chargées dans un DataFrame `df`. Si ce n'est pas le cas, vous pouvez ajouter :\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"02-14-2018-2.csv\")  \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 1. Suppression des Doublons\n",
    "\n",
    "Les doublons sont détectés et supprimés pour éviter la **redondance des données** :\n",
    "\n",
    "```python\n",
    "print(f\"Nombre de doublons avant suppression : {df.duplicated().sum()}\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Nombre de doublons après suppression : {df.duplicated().sum()}\")\n",
    "```\n",
    "\n",
    "- **Avant suppression**, on affiche le **nombre de lignes dupliquées**.\n",
    "- **Après suppression**, on vérifie qu'il ne reste plus de doublons.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 2. Traitement des Valeurs Manquantes\n",
    "\n",
    "Le script identifie et corrige les **valeurs nulles** dans le dataset.\n",
    "\n",
    "```python\n",
    "print(\"Valeurs manquantes avant traitement :\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "```\n",
    "\n",
    "Deux méthodes sont utilisées :\n",
    "1. **Remplacement par la médiane** pour les colonnes numériques :\n",
    "   ```python\n",
    "   for col in df.select_dtypes(include=[np.number]).columns:\n",
    "       df[col].fillna(df[col].median(), inplace=True)\n",
    "   ```\n",
    "   → Cela évite de **biaiser les distributions** en conservant une tendance centrale.\n",
    "\n",
    "2. **Suppression des lignes restantes contenant des valeurs manquantes** :\n",
    "   ```python\n",
    "   df.dropna(inplace=True)\n",
    "   ```\n",
    "   → Utile si certaines valeurs manquantes ne peuvent être remplacées.\n",
    "\n",
    "Enfin, on vérifie que **toutes les valeurs nulles ont été supprimées** :\n",
    "\n",
    "```python\n",
    "print(f\"Valeurs manquantes après traitement : {df.isnull().sum().sum()}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 3. Gestion des Valeurs Infinies et Aberrantes\n",
    "\n",
    "Le script identifie les **valeurs infinies** qui peuvent perturber les analyses.\n",
    "\n",
    "```python\n",
    "print(\"Vérification des valeurs infinies avant traitement :\")\n",
    "print(df.replace([np.inf, -np.inf], np.nan).isnull().sum()[df.replace([np.inf, -np.inf], np.nan).isnull().sum() > 0])\n",
    "```\n",
    "\n",
    "- Les valeurs **infinies** (`np.inf`, `-np.inf`) sont remplacées par **NaN** :\n",
    "  ```python\n",
    "  df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "  ```\n",
    "  → Cela évite des erreurs lors des calculs et visualisations.\n",
    "\n",
    "- On vérifie ensuite les **valeurs extrêmes** :\n",
    "  ```python\n",
    "  max_value = df.select_dtypes(include=[np.number]).max().max()\n",
    "  if max_value > 1e15:\n",
    "      df[df > 1e15] = np.nan\n",
    "      print(\"⚠️ Certaines valeurs étaient trop grandes et ont été remplacées par NaN.\")\n",
    "  ```\n",
    "  → Un seuil de **10¹⁵** est fixé pour identifier les valeurs anormalement élevées.\n",
    "\n",
    "- Après cela, toutes les valeurs `NaN` restantes sont supprimées :\n",
    "\n",
    "  ```python\n",
    "  df.dropna(inplace=True)\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 4. Vérification et Correction des Types de Données\n",
    "\n",
    "Le script affiche les types de données avant correction :\n",
    "\n",
    "```python\n",
    "print(\"Types de données avant transformation :\")\n",
    "print(df.dtypes)\n",
    "```\n",
    "\n",
    "- Il tente de **convertir les colonnes de type \"object\" en float** si possible :\n",
    "  ```python\n",
    "  for col in df.select_dtypes(include=['object']).columns:\n",
    "      try:\n",
    "          df[col] = df[col].astype(float)\n",
    "      except:\n",
    "          pass  # Certaines colonnes resteront du texte (ex: 'Label')\n",
    "  ```\n",
    "  → Cela est utile pour garantir que les **colonnes numériques sont bien exploitables**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 5. Encodage de la Colonne `Label` (Attaque vs Normal)\n",
    "\n",
    "Si le dataset contient une colonne `Label` indiquant **le type de trafic**, celle-ci est transformée en **valeurs numériques** (`0` pour normal et `1` pour attaque).\n",
    "\n",
    "```python\n",
    "if 'Label' in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    df['Label'] = le.fit_transform(df['Label'])\n",
    "```\n",
    "\n",
    "Après encodage, on affiche la distribution des labels :\n",
    "\n",
    "```python\n",
    "print(\"Distribution des labels après encodage :\")\n",
    "print(df['Label'].value_counts())\n",
    "```\n",
    "\n",
    "- Cette étape est cruciale pour **les modèles de Machine Learning**, qui ne traitent pas directement les catégories textuelles.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 6. Normalisation des Features Numériques (Standardisation)\n",
    "\n",
    "Toutes les **features numériques** sont normalisées à l'aide de la **standardisation** :\n",
    "\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "```\n",
    "\n",
    "- Cela transforme chaque **variable** pour qu'elle ait une **moyenne de 0** et un **écart-type de 1**.\n",
    "- Utile pour améliorer la **performance des modèles de classification**.\n",
    "\n",
    "Une confirmation est affichée :\n",
    "\n",
    "```python\n",
    "print(\"✅ Normalisation des features terminée.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 7. Sauvegarde des Données Nettoyées\n",
    "\n",
    "Les données nettoyées sont enregistrées dans un **nouveau fichier CSV** :\n",
    "\n",
    "```python\n",
    "df.to_csv(\"cleaned_02-14-2018-2.csv\", index=False)\n",
    "```\n",
    "\n",
    "Une confirmation est affichée :\n",
    "\n",
    "```python\n",
    "print(\"✅ Fichier cleaned_02-14-2018-2.csv enregistré avec succès !\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Conclusion\n",
    "\n",
    "Ce script effectue un **nettoyage avancé** des données, essentiel avant toute analyse ou modélisation. Il permet de :\n",
    "\n",
    "✔️ **Supprimer les doublons**  \n",
    "✔️ **Gérer les valeurs manquantes et infinies**  \n",
    "✔️ **Corriger les types de données**  \n",
    "✔️ **Encoder les labels**  \n",
    "✔️ **Standardiser les données numériques**  \n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 Améliorations Possibles\n",
    "\n",
    "Voici quelques pistes d'amélioration pour ce script :\n",
    "- **Ajouter une détection automatique des valeurs aberrantes** avec des méthodes comme **IQR (Interquartile Range)**.\n",
    "- **Générer des visualisations** pour identifier les **distributions** avant et après le traitement.\n",
    "- **Créer une pipeline de prétraitement** avec `sklearn.pipeline`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Résumé des Étapes en Code\n",
    "\n",
    "```python\n",
    "# 1. Suppression des doublons\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 2. Traitement des valeurs manquantes\n",
    "df.fillna(df.median(), inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 3. Gestion des valeurs infinies et aberrantes\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 4. Correction des types de données\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    try:\n",
    "        df[col] = df[col].astype(float)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 5. Encodage des labels\n",
    "if 'Label' in df.columns:\n",
    "    df['Label'] = LabelEncoder().fit_transform(df['Label'])\n",
    "\n",
    "# 6. Normalisation\n",
    "df[df.select_dtypes(include=[np.number]).columns] = StandardScaler().fit_transform(df.select_dtypes(include=[np.number]))\n",
    "\n",
    "# 7. Sauvegarde des données nettoyées\n",
    "df.to_csv(\"cleaned_02-14-2018-2.csvsv\", index=False)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 9. Deleting duplicates\n",
    "print(f\"\\n🔍 Nombre de doublons avant suppression : {df.duplicated().sum()}\")\n",
    "df = df.drop_duplicates()  # ✅ Suppression correcte sans inplace=True\n",
    "print(f\"✅ Nombre de doublons après suppression : {df.duplicated().sum()}\")\n",
    "\n",
    "# ✅ 10. Handling missing values\n",
    "print(\"\\n🔍 Valeurs manquantes avant traitement :\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# Replacement of missing values by the median for numerical columns\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    df.loc[:, col] = df[col].fillna(df[col].median())  # ✅ Use .loc[] to avoid chained copies\n",
    "\n",
    "# Deletion of remaining lines with zero values\n",
    "df = df.dropna()\n",
    "print(\"\\n✅ Valeurs manquantes après traitement :\", df.isnull().sum().sum())\n",
    "\n",
    "# ✅ 11. Handling infinite values and outliers\n",
    "print(\"\\n🔍 Vérification des valeurs infinies avant traitement :\")\n",
    "infinite_values = df.replace([np.inf, -np.inf], np.nan).isnull().sum()\n",
    "infinite_values = infinite_values[infinite_values > 0]\n",
    "print(infinite_values)\n",
    "\n",
    "# Replacing infinite values with NaN\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "print(\"\\n✅ Valeurs infinies remplacées par NaN.\")\n",
    "\n",
    "# Verify and remove extreme values (too large for dtype float64)\n",
    "max_value = df.select_dtypes(include=[np.number]).max().max()  # Find the largest numerical value\n",
    "if max_value > 1e15:  # Safety threshold to avoid extreme values\n",
    "    df.loc[:, df > 1e15] = np.nan\n",
    "    print(\"\\n⚠️ Certaines valeurs étaient trop grandes et ont été remplacées par NaN.\")\n",
    "\n",
    "# Removal of remaining NaN after infinity conversion\n",
    "df = df.dropna()\n",
    "print(\"\\n✅ Suppression des NaN après traitement des valeurs infinies et aberrantes.\")\n",
    "\n",
    "# ✅ 12. DateTime column management\n",
    "print(\"\\n🔍 Détection des colonnes datetime...\")\n",
    "datetime_cols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = pd.to_datetime(df[col])  # Convert if date\n",
    "        datetime_cols.append(col)\n",
    "        print(f\"📅 Converti '{col}' en format DateTime.\")\n",
    "    except (ValueError, TypeError):\n",
    "        pass  # Ignore if conversion fails\n",
    "\n",
    "if datetime_cols:\n",
    "    # Option 1: Extract useful features\n",
    "    for col in datetime_cols:\n",
    "        df[col + '_hour'] = df[col].dt.hour\n",
    "        df[col + '_day'] = df[col].dt.day\n",
    "        df[col + '_month'] = df[col].dt.month\n",
    "        df[col + '_weekday'] = df[col].dt.weekday\n",
    "    \n",
    "    # Option 2: Delete original datetime columns\n",
    "    df = df.drop(columns=datetime_cols)\n",
    "    print(f\"\\n✅ Colonnes datetime supprimées : {datetime_cols}\")\n",
    "\n",
    "# ✅ 13. Checking and correcting data types\n",
    "print(\"\\n🔍 Types de données avant transformation :\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert ill-typed columns to numeric (if possible)\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    try:\n",
    "        df.loc[:, col] = df[col].astype(float)  # ✅ Use .loc[] to avoid chained copies\n",
    "    except:\n",
    "        pass  # Some columns will remain as text (e.g. 'Label')\n",
    "\n",
    "# ✅ 14. Label column encoding (Attack vs Normal)\n",
    "if 'Label' in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    df.loc[:, 'Label'] = le.fit_transform(df['Label'])  # ✅ Using .loc[]\n",
    "\n",
    "print(\"\\n✅ Distribution des labels après encodage :\")\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "# ✅ 15. Standardization of digital features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df.loc[:, numerical_cols] = scaler.fit_transform(df[numerical_cols])  # ✅ Using .loc[]\n",
    "\n",
    "print(\"\\n✅ Normalisation des features terminée.\")\n",
    "\n",
    "# ✅ 16. Backup of cleaned data\n",
    "df.to_csv(\"cleaned_02-14-2018-2.csv\", index=False)\n",
    "print(\"\\n✅ Fichier cleaned_02-14-2018-2.csv enregistré avec succès !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Exploration et analyse des données :\n",
    "- Réalisez une analyse statistique descriptive.\n",
    "- Visualisez les données pour identifier les tendances et relations.\n",
    "- Formulez une hypothèse initiale à tester avec les modèles de Machine Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Analyse des Données Nettoyées avec Pandas, Seaborn et Matplotlib\n",
    "\n",
    "Ce script effectue une **analyse exploratoire approfondie** des données après nettoyage. Il inclut des statistiques descriptives, des visualisations de distribution et de corrélation pour mieux comprendre la structure du dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Prérequis\n",
    "\n",
    "Avant d'exécuter ce script, assurez-vous d'avoir installé les bibliothèques nécessaires avec :\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy seaborn matplotlib\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📂 Chargement des Données Nettoyées\n",
    "\n",
    "Le script charge un fichier CSV préalablement nettoyé :\n",
    "\n",
    "```python\n",
    "file_path = \"cleaned_02-14-2018-2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "```\n",
    "\n",
    "Si le fichier n'est pas dans le même répertoire, ajustez le **chemin du fichier**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 1. Aperçu des Premières Lignes\n",
    "\n",
    "Le script affiche un **échantillon des premières lignes** du dataset :\n",
    "\n",
    "```python\n",
    "print(\"\\n📌 Aperçu des données nettoyées :\")\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "Cela permet de **vérifier rapidement** la structure et le contenu des données.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 2. Statistiques Générales des Données\n",
    "\n",
    "Les **statistiques descriptives** des variables numériques sont affichées :\n",
    "\n",
    "```python\n",
    "print(\"\\n📌 Statistiques descriptives des variables numériques :\")\n",
    "print(df.describe())\n",
    "```\n",
    "\n",
    "Ce tableau permet d’obtenir :\n",
    "- **Moyenne (mean)**\n",
    "- **Médiane (50%)**\n",
    "- **Écart-type (std)**\n",
    "- **Valeurs minimales et maximales**\n",
    "- **Quartiles (25%, 75%)**\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 3. Vérification de la Distribution des Labels\n",
    "\n",
    "Le script visualise la **répartition des classes** (`Label` = trafic normal ou attaque) :\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x=df['Label'], palette=\"viridis\")\n",
    "plt.title(\"Répartition des classes (Attaque vs Normal)\")\n",
    "plt.xlabel(\"Type de trafic\")\n",
    "plt.ylabel(\"Nombre d'échantillons\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"Normal\", \"Attaque\"])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- Affiche **combien d'exemples** appartiennent à chaque classe.\n",
    "- Vérifie si le dataset est **équilibré ou déséquilibré**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 4. Vérification de la Distribution de Variables Clés\n",
    "\n",
    "Le script génère des **histogrammes** pour **analyser la distribution** des principales variables :\n",
    "\n",
    "```python\n",
    "features_to_plot = df.select_dtypes(include=[np.number]).columns[:6]\n",
    "df[features_to_plot].hist(figsize=(12, 8), bins=50, color='royalblue', edgecolor='black')\n",
    "plt.suptitle(\"Histogramme des principales features\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- Sélectionne les **6 premières variables numériques**.\n",
    "- Affiche leur **répartition** sous forme d’**histogrammes**.\n",
    "- Permet de détecter les **données asymétriques ou aberrantes**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 5. Matrice de Corrélation des Principales Features\n",
    "\n",
    "Le script affiche une **matrice de corrélation** entre les variables :\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"🔍 Matrice de Corrélation\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- Montre **la relation entre les variables**.\n",
    "- Permet d’**identifier les corrélations fortes** (positives ou négatives).\n",
    "- Utile pour détecter les variables **redondantes**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 6. Analyse des Relations entre Variables Clés\n",
    "\n",
    "Un **nuage de points** est généré pour observer la **relation entre deux variables** :\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df[features_to_plot[0]], y=df[features_to_plot[1]], hue=df['Label'], alpha=0.5, palette=\"coolwarm\")\n",
    "plt.title(f\"🔍 Relation entre {features_to_plot[0]} et {features_to_plot[1]}\")\n",
    "plt.xlabel(features_to_plot[0])\n",
    "plt.ylabel(features_to_plot[1])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- **Compare graphiquement deux variables** pour détecter une tendance.\n",
    "- Utilise la **couleur** pour différencier les classes (`Label`).\n",
    "- Permet de repérer **des patterns entre attaques et trafic normal**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 7. Analyse de la Distribution des Valeurs (Boxplots)\n",
    "\n",
    "Le script génère des **boxplots** pour analyser la distribution des variables :\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df[features_to_plot], palette=\"coolwarm\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Boxplot des principales features\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- Permet de détecter **les valeurs aberrantes** (outliers).\n",
    "- Compare **les distributions des variables** sous forme de quartiles.\n",
    "- Identifie les **variations de dispersion** entre les features.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Conclusion\n",
    "\n",
    "Ce script effectue une **analyse complète** des données nettoyées et permet de :\n",
    "✔️ Vérifier la **structure et les caractéristiques** du dataset  \n",
    "✔️ Observer la **répartition des classes (trafic normal vs attaque)**  \n",
    "✔️ Analyser la **distribution des variables numériques**  \n",
    "✔️ Identifier les **corrélations et tendances clés**  \n",
    "✔️ Détecter les **valeurs aberrantes et les déséquilibres**  \n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Résumé des Étapes en Code\n",
    "\n",
    "```python\n",
    "# 1. Chargement des données nettoyées\n",
    "df = pd.read_csv(\"cleaned_02-14-2018-2.csv\")\n",
    "\n",
    "# 2. Aperçu des données\n",
    "print(df.head())\n",
    "print(df.describe())\n",
    "\n",
    "# 3. Répartition des labels (trafic normal vs attaque)\n",
    "sns.countplot(x=df['Label'], palette=\"viridis\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Histogrammes des principales variables\n",
    "df[df.select_dtypes(include=[np.number]).columns[:6]].hist(figsize=(12, 8), bins=50, color='royalblue')\n",
    "plt.show()\n",
    "\n",
    "# 5. Matrice de corrélation\n",
    "sns.heatmap(df.corr(), cmap=\"coolwarm\")\n",
    "plt.show()\n",
    "\n",
    "# 6. Relation entre deux variables clés\n",
    "sns.scatterplot(x=df[features_to_plot[0]], y=df[features_to_plot[1]], hue=df['Label'], alpha=0.5, palette=\"coolwarm\")\n",
    "plt.show()\n",
    "\n",
    "# 7. Analyse des valeurs aberrantes avec boxplots\n",
    "sns.boxplot(data=df[features_to_plot], palette=\"coolwarm\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Exploration et analyse des données terminée !\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "file_path = \"cleaned_02-14-2018-2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 🔹 1. Preview of the first lines\n",
    "print(\"\\n📌 Aperçu des données nettoyées :\")\n",
    "print(df.head())\n",
    "\n",
    "# 🔹 2. General data statistics\n",
    "print(\"\\n📌 Statistiques descriptives des variables numériques :\")\n",
    "print(df.describe())\n",
    "\n",
    "# 🔹 3. Checking label distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x=df['Label'], palette=\"viridis\")\n",
    "plt.title(\"Répartition des classes (Attaque vs Normal)\")\n",
    "plt.xlabel(\"Type de trafic\")\n",
    "plt.ylabel(\"Nombre d'échantillons\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"Normal\", \"Attaque\"])\n",
    "plt.show()\n",
    "\n",
    "# 🔹 4. Checking the distribution of a few key variables\n",
    "features_to_plot = df.select_dtypes(include=[np.number]).columns[:6]  # Selects 6 numerical variables\n",
    "\n",
    "df[features_to_plot].hist(figsize=(12, 8), bins=50, color='royalblue', edgecolor='black')\n",
    "plt.suptitle(\"Histogramme des principales features\")\n",
    "plt.show()\n",
    "\n",
    "# 🔹 5. Correlation matrix of main features\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"🔍 Matrice de Corrélation\")\n",
    "plt.show()\n",
    "\n",
    "# 🔹 6. Analysis of relationships between key variables (e.g. duration vs. throughput)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df[features_to_plot[0]], y=df[features_to_plot[1]], hue=df['Label'], alpha=0.5, palette=\"coolwarm\")\n",
    "plt.title(f\"🔍 Relation entre {features_to_plot[0]} et {features_to_plot[1]}\")\n",
    "plt.xlabel(features_to_plot[0])\n",
    "plt.ylabel(features_to_plot[1])\n",
    "plt.show()\n",
    "\n",
    "# 🔹 7. Boxplot to analyze the distribution of values\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df[features_to_plot], palette=\"coolwarm\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Boxplot des principales features\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Exploration et analyse des données terminée !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Modélisation des données :\n",
    "\n",
    "- Sélectionnez un modèle de Machine Learning adapté.\n",
    "- Divisez les données en deux parties : Training et Test.\n",
    "- Entraînez, optimisez et évaluez les performances du modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Entraînement et Optimisation d'un Modèle de Machine Learning\n",
    "\n",
    "Ce script effectue **l'entraînement, l'évaluation et l'optimisation** d'un modèle de Machine Learning pour **classifier le trafic réseau** en \"Normal\" ou \"Attaque\" à l'aide de l'algorithme **Random Forest**. \n",
    "\n",
    "Il comprend :\n",
    "✔️ **Préparation des données**  \n",
    "✔️ **Sélection et entraînement du modèle**  \n",
    "✔️ **Évaluation des performances**  \n",
    "✔️ **Optimisation des hyperparamètres**  \n",
    "✔️ **Sauvegarde du modèle final**  \n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Prérequis\n",
    "\n",
    "Assurez-vous d'avoir installé les bibliothèques nécessaires avec :\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy seaborn matplotlib scikit-learn joblib\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 1. Chargement des Données Nettoyées\n",
    "\n",
    "Le dataset préalablement nettoyé est chargé dans un **DataFrame** :\n",
    "\n",
    "```python\n",
    "file_path = \"cleaned_02-14-2018.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "```\n",
    "\n",
    "**📌 Note** : Assurez-vous que le fichier est dans le bon répertoire ou ajustez le **chemin d'accès**.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 2. Séparation des Features (`X`) et de la Variable Cible (`y`)\n",
    "\n",
    "Les **features** (`X`) et la **cible** (`y`) sont séparées :\n",
    "\n",
    "```python\n",
    "X = df.drop(columns=['Label'])  # Features\n",
    "y = df['Label']  # Target\n",
    "```\n",
    "\n",
    "- `X` contient les variables explicatives.\n",
    "- `y` est la variable cible (`0 = Normal`, `1 = Attaque`).\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 3. Division en Jeu d'Entraînement et de Test (80/20)\n",
    "\n",
    "Le dataset est divisé en **80% d'entraînement** et **20% de test** :\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "```\n",
    "\n",
    "- **`stratify=y`** assure une distribution équilibrée des classes dans les ensembles d'entraînement et de test.\n",
    "- **Affichage des tailles des ensembles** :\n",
    "\n",
    "```python\n",
    "print(f\"- Entraînement : {X_train.shape[0]} échantillons\")\n",
    "print(f\"- Test : {X_test.shape[0]} échantillons\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 4. Sélection du Modèle de Machine Learning\n",
    "\n",
    "Le **modèle Random Forest** est choisi pour sa robustesse et sa capacité à gérer des données complexes :\n",
    "\n",
    "```python\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "```\n",
    "\n",
    "- **`n_estimators=100`** : Utilise **100 arbres** dans la forêt.\n",
    "- **`n_jobs=-1`** : Utilise **tous les cœurs disponibles** du processeur.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 5. Entraînement du Modèle\n",
    "\n",
    "Le modèle est entraîné sur l'ensemble d'apprentissage :\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Une confirmation est affichée après l'entraînement :\n",
    "\n",
    "```python\n",
    "print(\"\\n✅ Modèle entraîné avec succès !\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 6. Prédictions sur le Jeu de Test\n",
    "\n",
    "Les prédictions sont effectuées sur les **données de test** :\n",
    "\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 7. Évaluation des Performances du Modèle\n",
    "\n",
    "L'**exactitude (accuracy)** du modèle est calculée :\n",
    "\n",
    "```python\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n📊 Précision du modèle : {accuracy:.4f}\")\n",
    "```\n",
    "\n",
    "Un **rapport de classification** détaillé est affiché :\n",
    "\n",
    "```python\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 8. Matrice de Confusion\n",
    "\n",
    "Une **matrice de confusion** est générée pour évaluer les erreurs du modèle :\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Attaque\"], yticklabels=[\"Normal\", \"Attaque\"])\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Réel\")\n",
    "plt.title(\"🔍 Matrice de Confusion\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Cela permet d'identifier :\n",
    "- **Les vrais positifs et négatifs** (prédictions correctes).\n",
    "- **Les faux positifs et négatifs** (erreurs de classification).\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 9. Optimisation du Modèle avec GridSearchCV\n",
    "\n",
    "Le **tuning des hyperparamètres** est effectué avec `GridSearchCV` :\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1), \n",
    "                           param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Les **meilleurs hyperparamètres** sont affichés :\n",
    "\n",
    "```python\n",
    "print(f\"\\n✅ Meilleurs hyperparamètres trouvés : {grid_search.best_params_}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 10. Réentraînement avec les Meilleurs Paramètres\n",
    "\n",
    "Le **meilleur modèle** issu de GridSearch est récupéré et réentraîné :\n",
    "\n",
    "```python\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 11. Nouvelle Évaluation du Modèle Optimisé\n",
    "\n",
    "Le modèle optimisé est testé à nouveau :\n",
    "\n",
    "```python\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"\\n📊 Précision du modèle optimisé : {accuracy_best:.4f}\")\n",
    "```\n",
    "\n",
    "Un **nouveau rapport de classification** est affiché :\n",
    "\n",
    "```python\n",
    "print(\"\\n📌 Rapport de classification après optimisation :\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 12. Sauvegarde du Modèle Entraîné\n",
    "\n",
    "Le modèle final est sauvegardé au format `.pkl` avec `joblib` :\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "joblib.dump(best_model, \"final_model.pkl\")\n",
    "```\n",
    "\n",
    "Une confirmation est affichée :\n",
    "\n",
    "```python\n",
    "print(\"\\n✅ Modèle sauvegardé sous 'final_model.pkl'\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Résumé des Étapes\n",
    "\n",
    "```python\n",
    "# 1. Chargement des données nettoyées\n",
    "df = pd.read_csv(\"cleaned_02-14-2018.csv\")\n",
    "\n",
    "# 2. Séparation des features et de la cible\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# 3. Division des données en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 4. Modèle Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Prédictions et évaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 6. Matrice de confusion\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "# 7. Optimisation avec GridSearchCV\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "                           param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 8. Réévaluation du modèle optimisé\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(f\"Optimized Accuracy: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
    "\n",
    "# 9. Sauvegarde du modèle\n",
    "joblib.dump(best_model, \"final_model.pkl\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 2. Separate features (X) and target variable (y)\n",
    "X = df.drop(columns=['Label'])  # Features\n",
    "y = df['Label']  # Target\n",
    "\n",
    "# ✅ 3. Division into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\n📌 Taille des jeux de données :\")\n",
    "print(f\"- Entraînement : {X_train.shape[0]} échantillons\")\n",
    "print(f\"- Test : {X_test.shape[0]} échantillons\")\n",
    "\n",
    "# ✅ 4. Machine Learning model selection (Random Forest)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# ✅ 5. Model drive\n",
    "print(\"\\n🚀 Entraînement du modèle...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"\\n✅ Modèle entraîné avec succès !\")\n",
    "\n",
    "# ✅ 6. Test set predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ✅ 7. Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n📊 Précision du modèle : {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n📌 Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ✅ 8. Confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=[\"Normal\", \"Attaque\"], yticklabels=[\"Normal\", \"Attaque\"])\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Réel\")\n",
    "plt.title(\"🔍 Matrice de Confusion\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 9. Model optimization with GridSearchCV (Hyperparameter Tuning)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1), param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n✅ Meilleurs hyperparamètres trouvés : {grid_search.best_params_}\")\n",
    "\n",
    "# ✅ 10. Retraining with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# ✅ 11. New evaluation of the optimized model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"\\n📊 Précision du modèle optimisé : {accuracy_best:.4f}\")\n",
    "\n",
    "print(\"\\n📌 Rapport de classification après optimisation :\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# ✅ 12. Saving the trained model\n",
    "import joblib\n",
    "joblib.dump(best_model, \"final_model.pkl\")\n",
    "print(\"\\n✅ Modèle sauvegardé sous 'final_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Interprétation des résultats :\n",
    "- Analysez les résultats obtenus et validez (ou invalidez) votre hypothèse.\n",
    "- Tirez des conclusions et proposez des insights métiers basés sur votre analyse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Évaluation et Interprétation du Modèle Optimisé\n",
    "\n",
    "Ce script analyse les **performances** du modèle de classification entraîné et optimisé. Il génère des **métriques clés**, des **visualisations** (matrice de confusion, courbes ROC et précision-rappel) et met en évidence les **features les plus importantes**. Enfin, il propose une **interprétation métier** des résultats.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Prérequis\n",
    "\n",
    "Avant d'exécuter ce script, installez les bibliothèques nécessaires avec :\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy seaborn matplotlib scikit-learn\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 1. Rapport de Classification du Modèle Optimisé\n",
    "\n",
    "Le rapport de classification fournit un **résumé détaillé** des performances du modèle :\n",
    "\n",
    "```python\n",
    "print(\"\\n📌 Rapport de classification du modèle optimisé :\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "```\n",
    "\n",
    "- Affiche **précision (precision), rappel (recall), F1-score** et **support** pour chaque classe.\n",
    "- Utile pour voir si le modèle favorise une **classe** plus que l’autre.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 2. Matrice de Confusion (Analyse des Erreurs)\n",
    "\n",
    "La **matrice de confusion** visualise les **prédictions correctes et erronées** du modèle :\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(6, 4))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_best)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Normal\", \"Attaque\"], yticklabels=[\"Normal\", \"Attaque\"])\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Réel\")\n",
    "plt.title(\"🔍 Matrice de Confusion - Modèle Optimisé\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- **Les valeurs sur la diagonale** (haut gauche et bas droit) représentent les **prédictions correctes**.\n",
    "- **Les valeurs hors diagonale** montrent les **erreurs de classification**.\n",
    "- Permet d’analyser si le modèle **manque trop d’attaques (faux négatifs)** ou **prédit trop de faux positifs**.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 3. Analyse des Métriques Clés\n",
    "\n",
    "Les métriques sont extraites de la matrice de confusion :\n",
    "\n",
    "```python\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"\\n📊 Précision (Precision) : {precision:.4f}\")\n",
    "print(f\"📊 Rappel (Recall) : {recall:.4f}\")\n",
    "print(f\"📊 Score F1 : {f1_score:.4f}\")\n",
    "print(f\"📊 Exactitude (Accuracy) : {accuracy:.4f}\")\n",
    "```\n",
    "\n",
    "- **Précision (Precision)** : Taux de prédictions correctes parmi les **attaques détectées**.\n",
    "- **Rappel (Recall)** : Taux de **vraies attaques détectées** sur l’ensemble des attaques réelles.\n",
    "- **F1-score** : Moyenne harmonique entre précision et rappel (**équilibre entre faux positifs et faux négatifs**).\n",
    "- **Exactitude (Accuracy)** : Proportion d’échantillons **correctement classifiés**.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 4. Courbe ROC et AUC\n",
    "\n",
    "La **courbe ROC** permet de visualiser la capacité du modèle à **distinguer les classes** :\n",
    "\n",
    "```python\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]  # Probabilité de la classe \"Attaque\"\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonale de hasard\n",
    "plt.xlabel(\"Taux de Faux Positifs (FPR)\")\n",
    "plt.ylabel(\"Taux de Vrais Positifs (TPR)\")\n",
    "plt.title(\"🔍 Courbe ROC\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- **FPR (False Positive Rate)** : Proportion de **faux positifs**.\n",
    "- **TPR (True Positive Rate)** : Proportion de **vrais positifs**.\n",
    "- **AUC (Area Under Curve)** : Score global de la capacité du modèle à séparer les classes.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 5. Courbe Précision-Rappel\n",
    "\n",
    "La **courbe précision-rappel** est utile lorsque les classes sont **déséquilibrées** :\n",
    "\n",
    "```python\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(recall_vals, precision_vals, color='purple', lw=2)\n",
    "plt.xlabel(\"Rappel\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.title(\"🔍 Courbe Précision-Rappel\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- Permet d’analyser comment le **rappel** évolue en fonction de la **précision**.\n",
    "- Si la **précision chute rapidement**, cela signifie un **nombre élevé de faux positifs**.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 6. Analyse des Features les Plus Importantes\n",
    "\n",
    "Le modèle **Random Forest** permet d’identifier les **variables les plus influentes** :\n",
    "\n",
    "```python\n",
    "feature_importances = best_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)[-10:]  # Top 10 features\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align=\"center\")\n",
    "plt.yticks(range(len(sorted_idx)), [X.columns[i] for i in sorted_idx])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"📊 Top 10 des Features les Plus Importantes\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- Met en évidence les **10 variables les plus déterminantes** pour la prédiction.\n",
    "- Peut être utilisé pour **sélectionner les meilleures features** et améliorer le modèle.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 7. Interprétation des Résultats\n",
    "\n",
    "Le modèle est interprété en fonction des **métriques calculées** :\n",
    "\n",
    "```python\n",
    "print(\"\\n📌 🔍 Interprétation des résultats 🔍\")\n",
    "\n",
    "if accuracy > 0.90:\n",
    "    print(\"✅ Le modèle a une très bonne performance globale avec une précision élevée.\")\n",
    "elif accuracy > 0.80:\n",
    "    print(\"✅ Le modèle a une bonne précision, mais pourrait être amélioré.\")\n",
    "else:\n",
    "    print(\"⚠️ Le modèle a une précision faible. Il pourrait nécessiter un meilleur prétraitement ou un autre algorithme.\")\n",
    "\n",
    "print(\"\\n📌 Insights métiers :\")\n",
    "if precision < 0.80:\n",
    "    print(\"- ⚠️ Le taux de faux positifs est élevé, ce qui signifie que certaines connexions normales sont classées comme des attaques.\")\n",
    "if recall < 0.80:\n",
    "    print(\"- ⚠️ Le modèle manque certaines attaques (faux négatifs), ce qui peut poser un risque en cybersécurité.\")\n",
    "if f1_score > 0.85:\n",
    "    print(\"- ✅ Le compromis entre précision et rappel est bon, ce qui signifie que le modèle est fiable pour détecter les intrusions.\")\n",
    "if feature_importances.max() > 0.1:\n",
    "    print(\"- ✅ Certaines features sont très influentes. Un expert en cybersécurité peut analyser leur impact.\")\n",
    "\n",
    "print(\"\\n✅ Analyse terminée !\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Display of optimized model results\n",
    "print(\"\\n📌 Rapport de classification du modèle optimisé :\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# ✅ 2. Confusion matrix (error analysis)\n",
    "plt.figure(figsize=(6, 4))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_best)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Normal\", \"Attaque\"], yticklabels=[\"Normal\", \"Attaque\"])\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Réel\")\n",
    "plt.title(\"🔍 Matrice de Confusion - Modèle Optimisé\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 3. Analysis of key metrics\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"\\n📊 Précision (Precision) : {precision:.4f}\")\n",
    "print(f\"📊 Rappel (Recall) : {recall:.4f}\")\n",
    "print(f\"📊 Score F1 : {f1_score:.4f}\")\n",
    "print(f\"📊 Exactitude (Accuracy) : {accuracy:.4f}\")\n",
    "\n",
    "# ✅ 4. ROC and AUC curves\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the “Attack” class\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal of chance\n",
    "plt.xlabel(\"Taux de Faux Positifs (FPR)\")\n",
    "plt.ylabel(\"Taux de Vrais Positifs (TPR)\")\n",
    "plt.title(\"🔍 Courbe ROC\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 5. Precision-Recall curve\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(recall_vals, precision_vals, color='purple', lw=2)\n",
    "plt.xlabel(\"Rappel\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.title(\"🔍 Courbe Précision-Rappel\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 6. Analysis of the most important features\n",
    "feature_importances = best_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)[-10:]  # Top 10 features\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align=\"center\")\n",
    "plt.yticks(range(len(sorted_idx)), [X.columns[i] for i in sorted_idx])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"📊 Top 10 des Features les Plus Importantes\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 7. Interpretation of results\n",
    "print(\"\\n📌 🔍 Interprétation des résultats 🔍\")\n",
    "\n",
    "if accuracy > 0.90:\n",
    "    print(\"✅ Le modèle a une très bonne performance globale avec une précision élevée.\")\n",
    "elif accuracy > 0.80:\n",
    "    print(\"✅ Le modèle a une bonne précision, mais pourrait être amélioré.\")\n",
    "else:\n",
    "    print(\"⚠️ Le modèle a une précision faible. Il pourrait nécessiter un meilleur prétraitement ou un autre algorithme.\")\n",
    "\n",
    "print(\"\\n📌 Insights métiers :\")\n",
    "if precision < 0.80:\n",
    "    print(\"- ⚠️ Le taux de faux positifs est élevé, ce qui signifie que certaines connexions normales sont classées comme des attaques.\")\n",
    "if recall < 0.80:\n",
    "    print(\"- ⚠️ Le modèle manque certaines attaques (faux négatifs), ce qui peut poser un risque en cybersécurité.\")\n",
    "if f1_score > 0.85:\n",
    "    print(\"- ✅ Le compromis entre précision et rappel est bon, ce qui signifie que le modèle est fiable pour détecter les intrusions.\")\n",
    "if feature_importances.max() > 0.1:\n",
    "    print(\"- ✅ Certaines features sont très influentes. Un expert en cybersécurité peut analyser leur impact.\")\n",
    "\n",
    "print(\"\\n✅ Analyse terminée !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Communication des résultats :\n",
    "Créez des visualisations claires et pertinentes pour présenter vos résultats.\n",
    "Formulez des recommandations concrètes basées sur vos analyses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 1. Récapitulatif des performances\n",
    "accuracy_val = accuracy_score(y_test, y_pred_best)\n",
    "precision_val = precision_score(y_test, y_pred_best)\n",
    "recall_val = recall_score(y_test, y_pred_best)\n",
    "f1_val = f1_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"\\n📊 Récapitulatif des performances du modèle :\")\n",
    "print(f\"✅ Précision (Accuracy) : {accuracy:.4f}\")\n",
    "print(f\"✅ Précision (Precision) : {precision:.4f}\")\n",
    "print(f\"✅ Rappel (Recall) : {recall:.4f}\")\n",
    "print(f\"✅ Score F1 : {f1:.4f}\")\n",
    "\n",
    "# ✅ 2. Matrice de confusion avec annotations\n",
    "plt.figure(figsize=(6, 4))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_best)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Normal\", \"Attaque\"], yticklabels=[\"Normal\", \"Attaque\"])\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Réel\")\n",
    "plt.title(\"🔍 Matrice de Confusion - Résultats finaux\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 3. Courbe ROC et AUC\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]  # Probabilités pour la classe \"Attaque\"\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonale de hasard\n",
    "plt.xlabel(\"Taux de Faux Positifs (FPR)\")\n",
    "plt.ylabel(\"Taux de Vrais Positifs (TPR)\")\n",
    "plt.title(\"🔍 Courbe ROC\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 4. Courbe Precision-Recall\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(recall_vals, precision_vals, color='purple', lw=2)\n",
    "plt.xlabel(\"Rappel\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.title(\"🔍 Courbe Précision-Rappel\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 5. Importance des Features\n",
    "feature_importances = best_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)[-10:]  # Top 10 features\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align=\"center\")\n",
    "plt.yticks(range(len(sorted_idx)), [X.columns[i] for i in sorted_idx])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"📊 Top 10 des Features les Plus Importantes\")\n",
    "plt.show()\n",
    "\n",
    "# ✅ 6. Formulation des recommandations\n",
    "print(\"\\n📌 🔍 Recommandations basées sur les résultats 🔍\")\n",
    "\n",
    "if accuracy > 0.90:\n",
    "    print(\"✅ Le modèle est fiable avec une haute précision. Il peut être utilisé pour une première détection des menaces.\")\n",
    "elif accuracy > 0.80:\n",
    "    print(\"✅ Le modèle est performant mais peut être optimisé (ex: amélioration du dataset, hyperparamètres).\")\n",
    "else:\n",
    "    print(\"⚠️ Le modèle n'est pas encore optimal. Il faudrait explorer d'autres algorithmes ou améliorer la qualité des données.\")\n",
    "\n",
    "if precision < 0.80:\n",
    "    print(\"- ⚠️ Attention : Le taux de faux positifs est élevé, ce qui pourrait générer des alertes inutiles.\")\n",
    "if recall < 0.80:\n",
    "    print(\"- ⚠️ Attention : Le modèle ne détecte pas toutes les attaques, un ajustement est nécessaire.\")\n",
    "\n",
    "print(\"\\n📌 Actions recommandées :\")\n",
    "print(\"- Tester d'autres modèles (XGBoost, Deep Learning).\")\n",
    "print(\"- Améliorer les données en ajoutant d'autres logs réseau.\")\n",
    "print(\"- Ajuster les hyperparamètres du modèle pour un meilleur rappel.\")\n",
    "print(\"- Implémenter une détection en temps réel avec ce modèle.\")\n",
    "\n",
    "print(\"\\n✅ Communication des résultats terminée !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
